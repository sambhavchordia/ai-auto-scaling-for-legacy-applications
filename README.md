# AI-Powered Auto-Scaling System

An intelligent, real-time auto-scaling platform that uses machine learning to predict load patterns and automatically scale infrastructure.

## ğŸš€ Features

- **ML-powered forecasting**: Prophet + tree-based models to predict load up to 24h ahead
- **Real-time anomaly detection**: Isolation Forest flags unusual traffic and risk
- **Live dashboard**: React + TypeScript with WebSocket updates
- **Intelligent scaling**: Automated scale up/down decisions based on ML signals
- **K8s-ready**: Docker images and manifests for easy deploys

## ğŸ§­ Folder structure

```text
ai-auto-scaling-for-legacy-applications/
â”œâ”€ data/                      # Sample datasets
â”œâ”€ docker/                    # Dockerfiles and compose
â”œâ”€ docs/                      # Architecture, API, deployment, contributing
â”œâ”€ frontend/                  # React + TypeScript dashboard
â”‚  â”œâ”€ server/                 # Dev server (proxy / SSR helpers if needed)
â”‚  â””â”€ src/                    # UI components, features, hooks, services
â”œâ”€ k8s/                       # Kubernetes manifests
â”œâ”€ models/                    # Model artifacts (generated/loaded at runtime)
â”œâ”€ scripts/                   # Training, setup, benchmarking utilities
â”œâ”€ src/                       # Python backend (FastAPI)
â”‚  â”œâ”€ api/                    # Routes, middleware, WebSocket
â”‚  â”œâ”€ config/                 # Settings and logging
â”‚  â”œâ”€ services/               # Scaling + monitoring services
â”‚  â””â”€ utils/                  # Data loading, metrics, validators
â”œâ”€ tests/                     # Unit + integration tests
â”œâ”€ main.py                    # Backend entrypoint
â”œâ”€ Makefile                   # Common dev tasks
â”œâ”€ requirements*.txt          # Python dependencies
â””â”€ README.md
```

## ğŸ› ï¸ Tech stack

- **Backend**: FastAPI (Python 3.10+), Pydantic Settings, WebSockets
- **Frontend**: React, TypeScript, Vite, Tailwind, shadcn/ui, Recharts
- **ML**: Prophet, scikit-learn (Isolation Forest)
- **Ops**: Docker, Docker Compose, Kubernetes manifests

## âš™ï¸ Configuration

Backend settings are managed via environment variables (see `src/config/settings.py`). Key vars:

- `HOST` (default `0.0.0.0`)
- `PORT` (default `8000`)
- `DEBUG` (default `true`)
- `MODEL_PATH` (default `models/`)
- `SECRET_KEY`
- `CORS_ORIGINS` (default `[*]`)

You can place overrides in a local `.env` file at the repo root.

## ğŸ“¦ Backend: run locally

```bash
# 1) Create a virtual environment (recommended)
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\\Scripts\\activate

# 2) Install dependencies
pip install -r requirements.txt

# 3) (Optional) Train or prepare models
python scripts/train_models.py

# 4) Start the API
python main.py
# API will listen on http://localhost:8000

# Health check
curl http://localhost:8000/health
```

Common Make targets:

```bash
make install         # pip install -r requirements.txt
make run             # python src/api/main.py
make test            # run tests
make train           # train models
```

## ğŸ–¥ï¸ Frontend: run locally

```bash
cd frontend
npm install  # or pnpm i / bun i
npm run dev
# App runs on http://localhost:5173 (Vite default)
```

The frontend expects the backend at `http://localhost:8000` by default. Adjust proxy/base URLs in `frontend/src/config.ts` if needed.

## ğŸ³ Docker & Docker Compose

Build and run the backend in Docker:

```bash
docker build -t ai-autoscaling .
docker run -p 8000:8000 ai-autoscaling
```

Or use Compose (includes volumes and healthcheck):

```bash
docker compose -f docker/docker-compose.yml up --build
# API available at http://localhost:8000
```

## â˜ï¸ Deploy (Kubernetes)

K8s manifests are provided in `k8s/` for a simple deployment/service/ingress setup. Update image names and apply:

```bash
kubectl apply -f k8s/
```

## ğŸ§ª Testing

```bash
pip install -r requirements-dev.txt
pytest tests/ -v
```

## ğŸ“š Documentation

- Architecture: see `docs/ARCHITECTURE.md`
- API reference: see `docs/API.md`
- Deployment guide: see `docs/DEPLOYMENT.md`
- Contributing: see `docs/CONTRIBUTING.md`

## ğŸ“ Notes

- Sample data is provided in `data/`. You can plug in your own metrics/time-series.
- Model artifacts are read from `models/` (create if missing). Training scripts will populate it.

## ğŸ“„ License

MIT License â€” see `LICENSE` for details.
